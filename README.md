# real-time-sensor-pipeline
Real-time data pipeline using Kafka, Python, PostgreSQL, and CSV

This project demonstrates a real-time data ingestion and storage pipeline using Apache Kafka, Python, PostgreSQL, and CSV.

## ğŸ“Œ Tech Stack
- Apache Kafka
- Python 3
- PostgreSQL
- Libraries: `kafka-python`, `psycopg2`, `csv`, `json`

## ğŸ”„ Pipeline Flow
1. **Producer** generates simulated sensor data (temperature, humidity, timestamp).
2. **Kafka Consumer** listens to a topic and writes data to:
   - PostgreSQL database: `sensordb`, table: `sensor_data`
   - CSV file: `sensor_data.csv`

---

## ğŸ› ï¸ Setup Instructions

### âœ… Step 1: Start Zookeeper
```bash
zookeeper-server-start.bat ..\..\config\zookeeper.properties
âœ… Step 2: Start Kafka Server
bash
Copy
Edit
kafka-server-start.bat ..\..\config\server.properties
âœ… Step 3: Create Kafka Topic (Run Once)
bash
Copy
Edit
kafka-topics.bat --create --topic realtime-data --bootstrap-server localhost:9092
âœ… Step 4: Create PostgreSQL Database and Table
sql
Copy
Edit
CREATE DATABASE sensordb;

CREATE TABLE sensor_data (
    sensor_id VARCHAR(50),
    temperature FLOAT,
    humidity FLOAT,
    timestamp TIMESTAMP
);
âœ… Step 5: Run Python Scripts
Start Producer:
bash
Copy
Edit
py producer.py
Start Consumer:
bash
Copy
Edit
py consumer.py
ğŸ“‚ Directory Structure
Copy
Edit
KafkaRealTimeProject/
â”œâ”€â”€ producer.py
â”œâ”€â”€ consumer.py
â”œâ”€â”€ sensor_data.csv
â”œâ”€â”€ README.md
ğŸ™‹â€â™‚ï¸ Author
Nadeem Azad
GitHub: @noorazadnadeem
